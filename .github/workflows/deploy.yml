name: Cloud-Saver CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'
  MODEL_PATH: 'models/sac_agent.pth'
  SYNTHETIC_DATA_PATH: 'data/aws_synthetic_usage.csv'
  HYBRID_DATA_PATH: 'data/aws_hybrid_usage.csv'
  LOG_DIR: 'logs/'
  COST_EXPORT_PATH: 'data/aws_cost_export.csv'

jobs:
  setup:
    name: Setup and Lint
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true  # Critical for LFS files
    
    - uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Create directories
      run: |
        mkdir -p ${{ env.LOG_DIR }}
        mkdir -p models
        mkdir -p data
    
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          venv/
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install lint dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black
    
    - name: Run flake8
      run: |
        flake8 api/ test/ models/ analysis/ --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: Run black
      run: |
        black --check api/ test/ models/ analysis/

  test:
    name: Run Tests
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: ["unit", "api"]
    
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true
    
    - uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          venv/
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install "cachetools>=4.0,<5.0"
        pip install -r documents/requirements.txt --upgrade
        pip install pytest pytest-cov pytest-mock pandas numpy

    - name: Prepare test data
      run: |
        mkdir -p data
        cat <<EOF > ${{ env.COST_EXPORT_PATH }}
        date,service,cost,usage,usage_start_time
        2025-07-22,AWS CloudShell,6.23e-08,0.0043636076,2025-07-22T00:00:00
        2025-07-22,AWS Data Transfer,-6.23e-08,0.0,2025-07-22T00:00:00
        EOF
        
        echo "=== Data Validation ==="
        python -c "
        import pandas as pd
        df = pd.read_csv('${{ env.COST_EXPORT_PATH }}')
        print('Columns:', df.columns.tolist())
        print('Data types:\n', df.dtypes)
        print('Sample data:\n', df.head())
        "
    
    - name: Generate synthetic test data
      run: |
        python data/generate_aws_hybrid_usage.py || exit 1
        echo "=== Hybrid Data Validation ==="
        python -c "
        import pandas as pd
        df = pd.read_csv('${{ env.HYBRID_DATA_PATH }}')
        print('Columns:', df.columns.tolist())
        print('Rows:', len(df))
        "
        head -n 5 ${{ env.HYBRID_DATA_PATH }}
    
    - name: Run tests
      run: |
        if [ "${{ matrix.test-type }}" = "unit" ]; then
          pytest test/test_sac_agent.py -v --cov=models --cov-report=xml
        else
          pytest test/test_api.py -v --cov=api --cov-report=xml
        fi
    
    - name: Upload coverage
      uses: codecov/codecov-action@v4
      with:
        files: ./coverage.xml
        flags: ${{ matrix.test-type }}

  train:
    name: Train and Benchmark
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true
    
    - uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          venv/
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install "cachetools>=4.0,<5.0"
        pip install -r documents/requirements.txt --upgrade
        pip install torch scikit-learn pandas

    - name: Validate training data
      run: |
        echo "=== Synthetic Data ==="
        head -n 5 ${{ env.SYNTHETIC_DATA_PATH }}
        echo "=== Hybrid Data ==="
        python -c "
        import pandas as pd
        df = pd.read_csv('${{ env.HYBRID_DATA_PATH }}')
        print('Columns:', df.columns.tolist())
        print('Missing values:', df.isnull().sum())
        "
    
    - name: Train SAC model
      run: |
        python analysis/train_sac_agent.py \
          --train-data ${{ env.SYNTHETIC_DATA_PATH }} \
          --test-data ${{ env.HYBRID_DATA_PATH }} \
          --model-save-path ${{ env.MODEL_PATH }} \
          --log-dir ${{ env.LOG_DIR }} || exit 1
        
        echo "=== Model Validation ==="
        python -c "
        import torch
        model = torch.load('${{ env.MODEL_PATH }}')
        print('Model architecture:', model)
        "
    
    - name: Run benchmark
      run: |
        python analysis/benchmark_sac_vs_heuristic.py \
          --data ${{ env.HYBRID_DATA_PATH }} \
          --model ${{ env.MODEL_PATH }} \
          --output data/sac_vs_heuristic_comparison.csv
        
        echo "=== Benchmark Results ==="
        head -n 5 data/sac_vs_heuristic_comparison.csv
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: training-artifacts
        path: |
          ${{ env.MODEL_PATH }}
          data/sac_vs_heuristic_comparison.csv
          ${{ env.LOG_DIR }}/sac_agent.log

  deploy:
    name: Deploy API
    needs: train
    runs-on: ubuntu-latest
    environment: production
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true
    
    - uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          venv/
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install "cachetools>=4.0,<5.0"
        pip install -r documents/requirements.txt --upgrade
        pip install gunicorn torch
        pip install torch 
    
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: training-artifacts
        path: ./
    
    - name: Verify artifacts
      run: |
        echo "=== Model Check ==="
        python -c "
        import torch
        try:
            model = torch.load('${{ env.MODEL_PATH }}')
            print('Model loaded successfully')
        except Exception as e:
            print(f'Model load failed: {e}')
            exit(1)
        "
    
    - name: Start API server
      run: |
        nohup gunicorn -b 0.0.0.0:5000 \
          --access-logfile ${{ env.LOG_DIR }}/api.log \
          --error-logfile ${{ env.LOG_DIR }}/api_error.log \
          --timeout 120 \
          api.main:app &
        sleep 5  # Give server time to start
    
    - name: Run smoke tests
      run: |
        # Basic health check
        curl -v --retry 5 --retry-delay 5 --retry-connrefused http://localhost:5000/health
        
        # Test prediction endpoint with sample data
        SAMPLE_INSTANCE=$(jq -n --arg id "i-12345" '{instance_id: $id, state: [0.1, 0.2, 0.3, 0.4]}')
        curl -v -X POST http://localhost:5000/predict \
          -H "Content-Type: application/json" \
          -d "$SAMPLE_INSTANCE"

    - name: Verify artifacts
      run: |
        echo "=== Model Check ==="
        python -c "
        import torch
        try:
            model = torch.load('${{ env.MODEL_PATH }}')
            print('Model loaded successfully')
        except Exception as e:
            print(f'Model load failed: {e}')
            exit(1)
        "
    
    - name: Deploy to AWS (optional)
      if: false  # Set to true when AWS credentials are configured
      run: |
        echo "AWS deployment would happen here"